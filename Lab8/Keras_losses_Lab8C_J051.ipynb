{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-losses_Lab8C_J051.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/universeatmyfeet/DL/blob/master/Lab8/Keras_losses_Lab8C_J051.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZX8anbsht7g",
        "colab_type": "text"
      },
      "source": [
        "#Usage of loss functions\n",
        "\n",
        "A loss function (or objective function, or optimization score function) is one of the two parameters required to compile a model:\n",
        "\n",
        "```\n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "from keras import losses\n",
        "model.compile(loss=losses.mean_squared_error, optimizer='sgd')\n",
        "```\n",
        "\n",
        "You can either pass the name of an existing loss function, or pass a TensorFlow/Theano symbolic function that returns a scalar for each data-point and takes the following two arguments:\n",
        "\n",
        "1. y_true: True labels. TensorFlow/Theano tensor.\n",
        "2. y_pred: Predictions. TensorFlow/Theano tensor of the same shape as y_true.\n",
        "\n",
        "The actual optimized objective is the mean of the output array across all datapoints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJkG-1OvheZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='elu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='elu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N52J4-gdiJSF",
        "colab_type": "text"
      },
      "source": [
        "#mean_squared_error\n",
        "\n",
        "keras.losses.mean_squared_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX0QPq4UiMSl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEnK0HIRih01",
        "colab_type": "text"
      },
      "source": [
        "#mean_absolute_error\n",
        "\n",
        "keras.losses.mean_absolute_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJiGk6rmikKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_absolute_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zCL32z2iohf",
        "colab_type": "text"
      },
      "source": [
        "#mean_absolute_percentage_error\n",
        "\n",
        "keras.losses.mean_absolute_percentage_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbVaaKZ8iruw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_absolute_percentage_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDT2uAtfiuXH",
        "colab_type": "text"
      },
      "source": [
        "#mean_squared_logarithmic_error\n",
        "\n",
        "keras.losses.mean_squared_logarithmic_error(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tbm0lJwNixJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='mean_squared_logarithmic_error',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLY0Km_mi0PA",
        "colab_type": "text"
      },
      "source": [
        "#squared_hinge\n",
        "\n",
        "keras.losses.squared_hinge(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXoHk504i2e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='squared_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hc5-jeei5PL",
        "colab_type": "text"
      },
      "source": [
        "#hinge\n",
        "\n",
        "keras.losses.hinge(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkbwuZ5li7oL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRoSjzqNjCwi",
        "colab_type": "text"
      },
      "source": [
        "#categorical_hinge\n",
        "\n",
        "keras.losses.categorical_hinge(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOrswDfMjF__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_hinge',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF0cEwoxjIXn",
        "colab_type": "text"
      },
      "source": [
        "#logcosh\n",
        "\n",
        "keras.losses.logcosh(y_true, y_pred)\n",
        "\n",
        "Logarithm of the hyperbolic cosine of the prediction error.\n",
        "\n",
        "log(cosh(x)) is approximately equal to (x ** 2) / 2 for small x and to abs(x) - log(2) for large x. This means that 'logcosh' works mostly like the mean squared error, but will not be so strongly affected by the occasional wildly incorrect prediction.\n",
        "\n",
        "##Arguments\n",
        "\n",
        "1. y_true: tensor of true targets.\n",
        "2. y_pred: tensor of predicted targets.\n",
        "\n",
        "##Returns\n",
        "\n",
        "1. Tensor with one scalar loss entry per sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4A7M01bjLap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='logcosh',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ0bv-eXjbXu",
        "colab_type": "text"
      },
      "source": [
        "#categorical_crossentropy\n",
        "\n",
        "keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-XrpX7Ajd_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2hMi0U5jk4d",
        "colab_type": "text"
      },
      "source": [
        "#binary_crossentropy\n",
        "\n",
        "keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDLqW8otjnUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stvo_lw6jqcT",
        "colab_type": "text"
      },
      "source": [
        "#kullback_leibler_divergence\n",
        "\n",
        "keras.losses.kullback_leibler_divergence(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6MTeFaHjs4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='kullback_leibler_divergence',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co28pTxijuyE",
        "colab_type": "text"
      },
      "source": [
        "#poisson\n",
        "\n",
        "keras.losses.poisson(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7uvZNh_jxXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='poisson',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzJ8kS6Mj1iS",
        "colab_type": "text"
      },
      "source": [
        "#cosine_proximity\n",
        "\n",
        "keras.losses.cosine_proximity(y_true, y_pred, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgC8iO8Lj4Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile model using accuracy\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='cosine_proximity',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0X2fr_n5nWG",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTTuWc4FXa8L",
        "colab_type": "text"
      },
      "source": [
        "1)**mean_squared_error**\n",
        "\n",
        "Test loss: 0.003352416222123199\n",
        "\n",
        "\n",
        "Test accuracy: 0.9799\n",
        "\n",
        "2)**mean_absolute_error**\n",
        "\n",
        "Test loss: 0.0038889680898445095\n",
        "\n",
        "\n",
        "Test accuracy: 0.981\n",
        "\n",
        "3)**mean_absolute_percentage_error**\n",
        "\n",
        "Test loss: 1803200.477230715\n",
        "\n",
        "\n",
        "Test accuracy: 0.9819\n",
        "\n",
        "4)**mean_squared_logarithmic_error**\n",
        "\n",
        "Test loss: 0.0017203592830507266\n",
        "\n",
        "\n",
        "Test accuracy: 0.9807\n",
        "\n",
        "5)**squared_hinge**\n",
        "\n",
        "Test loss: 0.9018609205245972\n",
        "\n",
        "\n",
        "Test accuracy: 0.9803\n",
        "\n",
        "6)**hinge**\n",
        "\n",
        "Test loss: 0.901724101448059\n",
        "\n",
        "\n",
        "Test accuracy: 0.9833\n",
        "\n",
        "7)**categorical_hinge**\n",
        "\n",
        "Test loss: 0.03607132461245253\n",
        "\n",
        "\n",
        "Test accuracy: 0.982\n",
        "\n",
        "8)**logcosh**\n",
        "\n",
        "Test loss: 0.0015778261381334592\n",
        "\n",
        "\n",
        "Test accuracy: 0.981\n",
        "\n",
        "9)**categorical_crossentropy**\n",
        "\n",
        "Test loss: 0.23053656777290435\n",
        "\n",
        "\n",
        "Test accuracy: 0.9802\n",
        "\n",
        "10)**binary_crossentropy**\n",
        "\n",
        "Test loss: 0.04225646639997729\n",
        "\n",
        "\n",
        "Test accuracy: 0.996229995727539\n",
        "\n",
        "11)**kullback_leibler_divergence**\n",
        "\n",
        "Test loss: 0.21674129924554209\n",
        "\n",
        "\n",
        "Test accuracy: 0.9822\n",
        "\n",
        "12)**poisson**\n",
        "\n",
        "Test loss: 0.1220341134428978\n",
        "\n",
        "\n",
        "Test accuracy: 0.9826\n",
        "\n",
        "13)**cosine_proximity**\n",
        "\n",
        "Test loss: -0.9826041687011718\n",
        "\n",
        "\n",
        "Test accuracy: 0.9819"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtA4m9UVXcoB",
        "colab_type": "text"
      },
      "source": [
        "The best among all is **binary_crossentropy** with an accuracy of almost 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUtEuFR3X8Hv",
        "colab_type": "code",
        "outputId": "f80dbde7-2fdb-4431-e802-415ce036e87d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 10)\n",
        "Y_test =  to_categorical(Y_test, 10)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 66us/step - loss: 0.6725 - acc: 0.8875 - val_loss: 0.2719 - val_acc: 0.9018\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 0.2698 - acc: 0.9025 - val_loss: 0.2671 - val_acc: 0.9030\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.2571 - acc: 0.9046 - val_loss: 0.2511 - val_acc: 0.9064\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 3s 53us/step - loss: 0.2474 - acc: 0.9074 - val_loss: 0.2564 - val_acc: 0.9050\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.2409 - acc: 0.9094 - val_loss: 0.2542 - val_acc: 0.9049\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 0.2353 - acc: 0.9107 - val_loss: 0.2456 - val_acc: 0.9098\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 0.2308 - acc: 0.9122 - val_loss: 0.2368 - val_acc: 0.9106\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 3s 50us/step - loss: 0.2261 - acc: 0.9139 - val_loss: 0.2523 - val_acc: 0.9088\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 0.2225 - acc: 0.9149 - val_loss: 0.2252 - val_acc: 0.9136\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.2196 - acc: 0.9157 - val_loss: 0.2314 - val_acc: 0.9121\n",
            "Test loss: 0.23143027470111846\n",
            "Test accuracy: 0.9121199871063232\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5qKfVfSYckH",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 10**\n",
        "\n",
        "Test loss: 0.23143027470111846\n",
        "\n",
        "\n",
        "Test accuracy: 0.9121199871063232"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0VMCd9qYL72",
        "colab_type": "code",
        "outputId": "24f077da-2b24-44a8-ad11-c644d8a32be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        }
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "#import dataset\n",
        "(X_train, Y_train), (X_test, Y_test) = cifar100.load_data()\n",
        "\n",
        "#change shape from image to vector\n",
        "X_train = X_train.reshape(50000, 32 * 32 * 3)\n",
        "X_test = X_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "Y_train = to_categorical(Y_train, 100)\n",
        "Y_test =  to_categorical(Y_test, 100)\n",
        "\n",
        "#Model building\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072, )))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 6s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "50000/50000 [==============================] - 3s 68us/step - loss: 0.0680 - acc: 0.9893 - val_loss: 0.0490 - val_acc: 0.9900\n",
            "Epoch 2/10\n",
            "50000/50000 [==============================] - 3s 53us/step - loss: 0.0479 - acc: 0.9900 - val_loss: 0.0473 - val_acc: 0.9900\n",
            "Epoch 3/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.0458 - acc: 0.9901 - val_loss: 0.0468 - val_acc: 0.9900\n",
            "Epoch 4/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.0443 - acc: 0.9901 - val_loss: 0.0455 - val_acc: 0.9901\n",
            "Epoch 5/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.0432 - acc: 0.9902 - val_loss: 0.0452 - val_acc: 0.9900\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.0423 - acc: 0.9902 - val_loss: 0.0444 - val_acc: 0.9901\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 3s 53us/step - loss: 0.0414 - acc: 0.9903 - val_loss: 0.0443 - val_acc: 0.9901\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 3s 51us/step - loss: 0.0407 - acc: 0.9903 - val_loss: 0.0431 - val_acc: 0.9902\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.0399 - acc: 0.9904 - val_loss: 0.0440 - val_acc: 0.9902\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 3s 52us/step - loss: 0.0393 - acc: 0.9904 - val_loss: 0.0439 - val_acc: 0.9902\n",
            "Test loss: 0.04387838685512543\n",
            "Test accuracy: 0.9902030138015747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tndLiHaWYmt2",
        "colab_type": "text"
      },
      "source": [
        "**CIFAR 100**\n",
        "\n",
        "Test loss: 0.04387838685512543\n",
        "\n",
        "\n",
        "Test accuracy: 0.9902030138015747"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQdFjxlrYS4s",
        "colab_type": "code",
        "outputId": "892565c1-b796-40ac-e927-a2404a9c4768",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "Y_train = to_categorical(Y_train, NUM_CLASSES)\n",
        "Y_test = to_categorical(Y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, Y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, Y_test))\n",
        "\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.0942 - acc: 0.9619 - val_loss: 0.0786 - val_acc: 0.9679\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 2s 37us/step - loss: 0.0672 - acc: 0.9730 - val_loss: 0.0769 - val_acc: 0.9682\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0604 - acc: 0.9757 - val_loss: 0.0644 - val_acc: 0.9750\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0561 - acc: 0.9774 - val_loss: 0.0597 - val_acc: 0.9767\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0529 - acc: 0.9788 - val_loss: 0.0624 - val_acc: 0.9752\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0505 - acc: 0.9798 - val_loss: 0.0666 - val_acc: 0.9748\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0491 - acc: 0.9804 - val_loss: 0.0645 - val_acc: 0.9761\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 2s 36us/step - loss: 0.0471 - acc: 0.9812 - val_loss: 0.0711 - val_acc: 0.9741\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 2s 39us/step - loss: 0.0458 - acc: 0.9820 - val_loss: 0.0575 - val_acc: 0.9788\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 2s 38us/step - loss: 0.0444 - acc: 0.9824 - val_loss: 0.0627 - val_acc: 0.9776\n",
            "Test loss: 0.06269588343054056\n",
            "Test accuracy: 0.9776000038146972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMiUNdpOYvjX",
        "colab_type": "text"
      },
      "source": [
        "**FASHION_MNIST**\n",
        "\n",
        "Test loss: 0.06269588343054056\n",
        "\n",
        "\n",
        "Test accuracy: 0.9776000038146972"
      ]
    }
  ]
}