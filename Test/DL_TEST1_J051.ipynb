{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_TEST1_J051.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/universeatmyfeet/DL/blob/master/Test/DL_TEST1_J051.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fInX34Gk563B",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "DL TEST 1 (J051)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SyXwp3N56li",
        "colab_type": "text"
      },
      "source": [
        "DATASET- MNIST, Task 1, 2 and 3 - Choose a dataset , divide train test , build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsFgMJLexG_l",
        "colab_type": "code",
        "outputId": "63b2f0a7-02f4-4522-d32d-dfe26436d0c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.2278 - acc: 0.9306 - val_loss: 0.1276 - val_acc: 0.9571\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0851 - acc: 0.9737 - val_loss: 0.0879 - val_acc: 0.9733\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0572 - acc: 0.9819 - val_loss: 0.0773 - val_acc: 0.9772\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0421 - acc: 0.9869 - val_loss: 0.0964 - val_acc: 0.9733\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0321 - acc: 0.9902 - val_loss: 0.0805 - val_acc: 0.9784\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0246 - acc: 0.9923 - val_loss: 0.0880 - val_acc: 0.9777\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0188 - acc: 0.9944 - val_loss: 0.1049 - val_acc: 0.9761\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0176 - acc: 0.9946 - val_loss: 0.0981 - val_acc: 0.9799\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0146 - acc: 0.9957 - val_loss: 0.1049 - val_acc: 0.9799\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0117 - acc: 0.9966 - val_loss: 0.0986 - val_acc: 0.9821\n",
            "Test loss: 0.09857604046542606\n",
            "Test accuracy: 0.9821\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXL9Q59Y6LL4",
        "colab_type": "text"
      },
      "source": [
        "Task 4 - performance of different optimizers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVBjdo-H6Ns4",
        "colab_type": "text"
      },
      "source": [
        "1)SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozKOSJLk6K4m",
        "colab_type": "code",
        "outputId": "dab44b09-aafb-4798-d070-3dbaa8451867",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "sgd=keras.optimizers.SGD(lr=0.01, momentum=0.0, nesterov=False)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=sgd,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0920 - val_acc: 0.9842\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 100us/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0903 - val_acc: 0.9844\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0020 - acc: 0.9995 - val_loss: 0.0893 - val_acc: 0.9846\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 103us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0886 - val_acc: 0.9843\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 101us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0882 - val_acc: 0.9843\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0878 - val_acc: 0.9841\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0876 - val_acc: 0.9843\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 97us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0873 - val_acc: 0.9843\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0871 - val_acc: 0.9844\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 98us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0870 - val_acc: 0.9841\n",
            "Test loss: 0.08699990694499975\n",
            "Test accuracy: 0.9841\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icu-rBqi6VZ_",
        "colab_type": "text"
      },
      "source": [
        "#2)RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DelSaxAmxHCq",
        "colab_type": "code",
        "outputId": "dcee3235-c284-431b-e59b-74fc95aa6cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "rms=keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=rms,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0119 - acc: 0.9965 - val_loss: 0.1059 - val_acc: 0.9821\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0081 - acc: 0.9975 - val_loss: 0.1051 - val_acc: 0.9820\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.1143 - val_acc: 0.9822\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0081 - acc: 0.9976 - val_loss: 0.1430 - val_acc: 0.9803\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.1201 - val_acc: 0.9822\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0068 - acc: 0.9981 - val_loss: 0.1121 - val_acc: 0.9840\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1209 - val_acc: 0.9836\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1320 - val_acc: 0.9833\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1387 - val_acc: 0.9829\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1642 - val_acc: 0.9788\n",
            "Test loss: 0.16419899174034067\n",
            "Test accuracy: 0.9788\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Da9RywZg6byd",
        "colab_type": "text"
      },
      "source": [
        "3)Adagrad"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMM01X6CxHIA",
        "colab_type": "code",
        "outputId": "da28448f-fbfc-4535-c96c-8582b3d506a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "ada=keras.optimizers.Adagrad(lr=0.01)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=ada,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0335 - acc: 0.9953 - val_loss: 0.1362 - val_acc: 0.9818\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.1295 - val_acc: 0.9836\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 6s 107us/step - loss: 3.2604e-04 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9831\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.9272e-04 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9829\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8789e-04 - acc: 1.0000 - val_loss: 0.1275 - val_acc: 0.9830\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8557e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9830\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 108us/step - loss: 2.8394e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9830\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8267e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9830\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 109us/step - loss: 2.8165e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9831\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 2.8082e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9832\n",
            "Test loss: 0.12741542895332614\n",
            "Test accuracy: 0.9832\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myAAG0U36kh3",
        "colab_type": "text"
      },
      "source": [
        "4)Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5MlR2-5xHF_",
        "colab_type": "code",
        "outputId": "098b14f5-8e6d-498f-c101-ccd9bb555cc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adelta=keras.optimizers.Adadelta(lr=1.0, rho=0.95)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adelta,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 9s 142us/step - loss: 2.8015e-04 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9835\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 133us/step - loss: 2.7826e-04 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9836\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 2.7700e-04 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9836\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 134us/step - loss: 2.7615e-04 - acc: 1.0000 - val_loss: 0.1273 - val_acc: 0.9836\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 2.7547e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9836\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 2.7493e-04 - acc: 1.0000 - val_loss: 0.1274 - val_acc: 0.9836\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 137us/step - loss: 2.7450e-04 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9835\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 2.7414e-04 - acc: 1.0000 - val_loss: 0.1276 - val_acc: 0.9834\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 136us/step - loss: 2.7383e-04 - acc: 1.0000 - val_loss: 0.1277 - val_acc: 0.9834\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 135us/step - loss: 2.7355e-04 - acc: 1.0000 - val_loss: 0.1277 - val_acc: 0.9833\n",
            "Test loss: 0.12774236969797348\n",
            "Test accuracy: 0.9833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRMiMCib6roR",
        "colab_type": "text"
      },
      "source": [
        "# 5)Adam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZleaE736wPDW",
        "colab_type": "code",
        "outputId": "4568a2f3-3523-4e1f-c2a0-43f1d25e91ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adam=keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0215 - acc: 0.9953 - val_loss: 0.1446 - val_acc: 0.9803\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0150 - acc: 0.9960 - val_loss: 0.1525 - val_acc: 0.9780\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0120 - acc: 0.9966 - val_loss: 0.1372 - val_acc: 0.9789\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0131 - acc: 0.9964 - val_loss: 0.1114 - val_acc: 0.9818\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.1477 - val_acc: 0.9773\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0113 - acc: 0.9970 - val_loss: 0.1177 - val_acc: 0.9815\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0150 - acc: 0.9961 - val_loss: 0.1499 - val_acc: 0.9785\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1109 - val_acc: 0.9814\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0087 - acc: 0.9974 - val_loss: 0.1142 - val_acc: 0.9816\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0101 - acc: 0.9972 - val_loss: 0.1183 - val_acc: 0.9802\n",
            "Test loss: 0.11832725769197851\n",
            "Test accuracy: 0.9802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUlHjd5y6zhN",
        "colab_type": "text"
      },
      "source": [
        "6)Adamax\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9Dp_zTk63N4",
        "colab_type": "code",
        "outputId": "f7973748-6f3f-428a-a6e4-d562cb3085c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 128us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1006 - val_acc: 0.9851\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 3.2098e-04 - acc: 1.0000 - val_loss: 0.0984 - val_acc: 0.9853\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 2.8815e-04 - acc: 1.0000 - val_loss: 0.0985 - val_acc: 0.9854\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.8161e-04 - acc: 1.0000 - val_loss: 0.0993 - val_acc: 0.9854\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.7787e-04 - acc: 1.0000 - val_loss: 0.1003 - val_acc: 0.9855\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 2.7519e-04 - acc: 1.0000 - val_loss: 0.1017 - val_acc: 0.9858\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.7314e-04 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 0.9856\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 2.7172e-04 - acc: 1.0000 - val_loss: 0.1047 - val_acc: 0.9861\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.7067e-04 - acc: 1.0000 - val_loss: 0.1063 - val_acc: 0.9860\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 2.6997e-04 - acc: 1.0000 - val_loss: 0.1084 - val_acc: 0.9859\n",
            "Test loss: 0.10838720070191052\n",
            "Test accuracy: 0.9859\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MP3TWcy7Dl3",
        "colab_type": "text"
      },
      "source": [
        "7)Nadam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Wjm_qY63vL",
        "colab_type": "code",
        "outputId": "88facadd-9183-461b-af10-32797f160c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "from keras import optimizers\n",
        "nadam=keras.optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "\n",
        "# Compile model using above optimizer\n",
        "model.compile(optimizer=nadam,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 8s 141us/step - loss: 0.0335 - acc: 0.9926 - val_loss: 0.1543 - val_acc: 0.9761\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0209 - acc: 0.9942 - val_loss: 0.1385 - val_acc: 0.9777\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0248 - acc: 0.9938 - val_loss: 0.1340 - val_acc: 0.9783\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 8s 132us/step - loss: 0.0196 - acc: 0.9945 - val_loss: 0.1152 - val_acc: 0.9791\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0205 - acc: 0.9944 - val_loss: 0.1110 - val_acc: 0.9786\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 8s 129us/step - loss: 0.0227 - acc: 0.9935 - val_loss: 0.1206 - val_acc: 0.9789\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0140 - acc: 0.9963 - val_loss: 0.1207 - val_acc: 0.9792\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0148 - acc: 0.9958 - val_loss: 0.1133 - val_acc: 0.9802\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 8s 130us/step - loss: 0.0188 - acc: 0.9950 - val_loss: 0.1530 - val_acc: 0.9788\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 8s 131us/step - loss: 0.0174 - acc: 0.9956 - val_loss: 0.1122 - val_acc: 0.9809\n",
            "Test loss: 0.11216217061202419\n",
            "Test accuracy: 0.9809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBWuVjxf7KDK",
        "colab_type": "text"
      },
      "source": [
        "Task 5 - list hyperparameter settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtBAZjtw63tQ",
        "colab_type": "code",
        "outputId": "e6c9ed77-12b4-4e03-9efd-fae6f221c791",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "from keras import optimizers\n",
        "import keras\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "adamax=keras.optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999)\n",
        "# Compile model using above optimizer\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 20\n",
        "\n",
        "# Load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.compile(optimizer=adamax,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 8s 127us/step - loss: 0.2394 - acc: 0.9303 - val_loss: 0.1217 - val_acc: 0.9614\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 7s 122us/step - loss: 0.0995 - acc: 0.9711 - val_loss: 0.0826 - val_acc: 0.9749\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0650 - acc: 0.9800 - val_loss: 0.0763 - val_acc: 0.9748\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0462 - acc: 0.9855 - val_loss: 0.0661 - val_acc: 0.9791\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0320 - acc: 0.9904 - val_loss: 0.0586 - val_acc: 0.9810\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0235 - acc: 0.9931 - val_loss: 0.0578 - val_acc: 0.9804\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0170 - acc: 0.9952 - val_loss: 0.0633 - val_acc: 0.9802\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0117 - acc: 0.9972 - val_loss: 0.0608 - val_acc: 0.9815\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0089 - acc: 0.9977 - val_loss: 0.0686 - val_acc: 0.9810\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 0.0057 - acc: 0.9987 - val_loss: 0.0615 - val_acc: 0.9829\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0628 - val_acc: 0.9823\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0672 - val_acc: 0.9822\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0018 - acc: 0.9998 - val_loss: 0.0631 - val_acc: 0.9832\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.0681 - val_acc: 0.9828\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 8.5229e-04 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9821\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 7.2427e-04 - acc: 0.9999 - val_loss: 0.0764 - val_acc: 0.9818\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0730 - val_acc: 0.9823\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 3.9254e-04 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 0.9836\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 2.3736e-04 - acc: 1.0000 - val_loss: 0.0828 - val_acc: 0.9807\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 4.2459e-04 - acc: 0.9999 - val_loss: 0.0726 - val_acc: 0.9837\n",
            "Test loss: 0.07261015367465329\n",
            "Test accuracy: 0.9837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8y-zmhto7U6k",
        "colab_type": "text"
      },
      "source": [
        "Task 6 - plot epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7ZaC6tb63p5",
        "colab_type": "code",
        "outputId": "11437cef-73cc-444c-fd16-582e6fb69149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "#Training\n",
        "history = model.fit(X_train, y_train, batch_size=128, nb_epoch=10, verbose=1, validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            " 1664/60000 [..............................] - ETA: 6s - loss: 0.0074 - acc: 0.9976"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0101 - acc: 0.9966 - val_loss: 0.1019 - val_acc: 0.9806\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.1201 - val_acc: 0.9803\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0079 - acc: 0.9977 - val_loss: 0.1245 - val_acc: 0.9796\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.1399 - val_acc: 0.9806\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0070 - acc: 0.9981 - val_loss: 0.1231 - val_acc: 0.9828\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1269 - val_acc: 0.9831\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1316 - val_acc: 0.9807\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0058 - acc: 0.9984 - val_loss: 0.1396 - val_acc: 0.9815\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1351 - val_acc: 0.9833\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0052 - acc: 0.9986 - val_loss: 0.1473 - val_acc: 0.9814\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFhm8Wdw63m_",
        "colab_type": "code",
        "outputId": "ccd2a78a-b61d-4fbb-c8da-aead362ef913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Plot training & validation accuracy values\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZmZ541AxM7O8+f/vR6m5+k2K8wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCggREYmlgBARkVj/HwlzK+x0wNu1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqoGjfN27dDG",
        "colab_type": "text"
      },
      "source": [
        "Task 7 - model summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRPIgcef63kG",
        "colab_type": "code",
        "outputId": "2798df5d-eee9-43b3-9921-12afd9d4db36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "#Model Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 535,818\n",
            "Trainable params: 535,818\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTpjudVZ63gk",
        "colab_type": "code",
        "outputId": "1e3e9a7f-bdc7-4d66-e737-5082decb5ceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "source": [
        "+from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "# Output network visualization\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"352pt\" viewBox=\"0.00 0.00 181.00 264.00\" width=\"241pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1.3333 1.3333) rotate(0) translate(4 260)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-260 177,-260 177,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140275010185872 -->\n<g class=\"node\" id=\"node1\">\n<title>140275010185872</title>\n<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 173,-255.5 173,-219.5 0,-219.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-233.8\">dense_1_input: InputLayer</text>\n</g>\n<!-- 140276544970648 -->\n<g class=\"node\" id=\"node2\">\n<title>140276544970648</title>\n<polygon fill=\"none\" points=\"33,-146.5 33,-182.5 140,-182.5 140,-146.5 33,-146.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-160.8\">dense_1: Dense</text>\n</g>\n<!-- 140275010185872&#45;&gt;140276544970648 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140275010185872-&gt;140276544970648</title>\n<path d=\"M86.5,-219.4551C86.5,-211.3828 86.5,-201.6764 86.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-192.5903 86.5,-182.5904 83.0001,-192.5904 90.0001,-192.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140275010184248 -->\n<g class=\"node\" id=\"node3\">\n<title>140275010184248</title>\n<polygon fill=\"none\" points=\"33,-73.5 33,-109.5 140,-109.5 140,-73.5 33,-73.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-87.8\">dense_2: Dense</text>\n</g>\n<!-- 140276544970648&#45;&gt;140275010184248 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140276544970648-&gt;140275010184248</title>\n<path d=\"M86.5,-146.4551C86.5,-138.3828 86.5,-128.6764 86.5,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-119.5903 86.5,-109.5904 83.0001,-119.5904 90.0001,-119.5903\" stroke=\"#000000\"/>\n</g>\n<!-- 140274997165192 -->\n<g class=\"node\" id=\"node4\">\n<title>140274997165192</title>\n<polygon fill=\"none\" points=\"33,-.5 33,-36.5 140,-36.5 140,-.5 33,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"86.5\" y=\"-14.8\">dense_3: Dense</text>\n</g>\n<!-- 140275010184248&#45;&gt;140274997165192 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140275010184248-&gt;140274997165192</title>\n<path d=\"M86.5,-73.4551C86.5,-65.3828 86.5,-55.6764 86.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"90.0001,-46.5903 86.5,-36.5904 83.0001,-46.5904 90.0001,-46.5903\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    }
  ]
}